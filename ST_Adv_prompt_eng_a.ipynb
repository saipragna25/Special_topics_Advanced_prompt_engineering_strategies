{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp1aAO91gujM7DrxV/4gfo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saipragna25/Special_topics_Advanced_prompt_engineering_strategies/blob/main/ST_Adv_prompt_eng_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n90F2tc2AdX4",
        "outputId": "444b2429-82cc-446a-e81b-0048bcbe752e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Setting up OpenAI API key\n",
        "api_key = \"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\"\n"
      ],
      "metadata": {
        "id": "wAQbg_7KICcc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ICL (In-Context Learning) Modified Messages:**\n",
        "\n",
        "In-Context Learning (ICL) is a technique that enables the model to retain and utilize information from the conversation context to provide more accurate and relevant responses. By feeding a sequence of messages including a system instruction, user queries, and model responses, ICL helps in building a coherent conversation where the model can reference prior interactions to understand the current query better. This technique is particularly useful in scenarios where conversations evolve with new information being introduced, requiring the model to adapt and respond in a contextually aware manner."
      ],
      "metadata": {
        "id": "RLIV-Y2EIgX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "success case:"
      ],
      "metadata": {
        "id": "zIV--jt0IlC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an assistant specialized in providing information about geographical locations.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me about the Amazon Rainforest.\"}\n",
        "]\n",
        "\n",
        "# Initializing the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Getting the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the reply\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2KPyRxhIhl7",
        "outputId": "80b17a2f-9c86-4ae8-b1cf-eeb4710c26af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Amazon Rainforest is a vast and diverse region located in South America, predominantly covering parts of Brazil, as well as extending into other countries including Peru, Colombia, Venezuela, Ecuador, Bolivia, Guyana, Suriname, and French Guiana. It is the largest tropical rainforest in the world, covering an area of approximately 5.5 million square kilometers.\n",
            "\n",
            "The Amazon Rainforest is renowned for its incredible biodiversity, housing an estimated 10% of all known species on Earth. It is home to thousands of plant species, around 2,500 tree species, and countless animal species, including mammals, birds, reptiles, amphibians, and insects. Notable inhabitants of the rainforest include jaguars, giant river otters, sloths, macaws, anacondas, and capybaras, among others.\n",
            "\n",
            "The Amazon Rainforest plays a vital role in regulating the Earth's climate, producing approximately 20% of the world's oxygen. It also helps in controlling the global carbon cycle by absorbing and storing huge amounts of carbon dioxide. Additionally, it functions as a natural buffer against climate change, acting as a major source of cooling and rainfall for the entire region.\n",
            "\n",
            "Furthermore, the Amazon Rainforest is home to numerous indigenous communities, some of which have inhabited the region for thousands of years, preserving their unique cultures and traditions. These communities rely on the forest for food, shelter, and medicinal plants.\n",
            "\n",
            "Unfortunately, the Amazon Rainforest faces various threats, such as deforestation, illegal logging, mining, agriculture expansion, and climate change. These activities not only endanger the rich biodiversity of the region but also impact the indigenous communities and contribute to global environmental issues.\n",
            "\n",
            "Efforts are being made by governments, organizations, and individuals to protect and conserve the Amazon Rainforest through initiatives such as establishing protected areas, enforcing stricter environmental regulations, and promoting sustainable practices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failure Case for In-Context Learning"
      ],
      "metadata": {
        "id": "_2-nnrEcI3nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an assistant specialized in providing information about geographical locations.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me about the Amazon Rainforest.\"},\n",
        "    {\"role\": \"user\", \"content\": \"is it going to rain today in the Amazon Rainforest?\"}\n",
        "]\n",
        "\n",
        "# Initializing the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Getting the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the reply\n",
        "print(reply)\n",
        "\n"
      ],
      "metadata": {
        "id": "kgfpUESOI6Qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f971e650-cfd3-44cd-84fc-5258ef38e788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI, I don't have real-time weather data. However, the Amazon Rainforest is known for its high humidity and heavy rainfall throughout the year. It experiences a tropical climate with no distinct dry season. On average, it receives about 9 feet (2.7 meters) of rainfall annually. So, it is highly likely that there is some amount of rainfall happening in the Amazon Rainforest on any given day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success case: In-Context Learning"
      ],
      "metadata": {
        "id": "zM8NQLFpJyh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a travel assistant specializing in creating personalized travel itineraries.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Plan a 7-day trip to Brazil.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Certainly! Here's a suggestion for your 7-day trip to Brazil:\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Day 1: Arrive in Rio de Janeiro and explore the famous Copacabana Beach.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Sounds good. Tell me more about Copacabana Beach.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Copacabana Beach is one of the most famous and vibrant beaches in Brazil, known for its golden sands and bustling atmosphere.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Where can I have a good Brazilian BBQ nearby?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Then continue with the itinerary for my 7 day trip to Brazil\"}\n",
        "]\n",
        "\n",
        "# Initializing the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Getting the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the reply\n",
        "print(reply)\n",
        "\n"
      ],
      "metadata": {
        "id": "jY2AyeznJ0Gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357d4d12-8a81-4ff8-83da-fdadeb450e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here's the rest of the itinerary:\n",
            "\n",
            "Day 2: Take a hike to the iconic Christ the Redeemer statue on Corcovado Mountain. Enjoy stunning panoramic views of Rio de Janeiro from the top.\n",
            "\n",
            "Day 3: Visit the vibrant neighborhood of Santa Teresa and explore its charming streets filled with art galleries, cafes, and historic buildings. Don't miss the opportunity to ride the iconic yellow tram, known as the Santa Teresa tram.\n",
            "\n",
            "Day 4: Fly to Iguazu Falls, one of the most stunning natural wonders in the world. Spend the day exploring the falls from both the Brazilian and Argentine sides, marveling at the spectacular views and taking boat rides to get up close to the cascades.\n",
            "\n",
            "Day 5: Fly to Salvador, the colorful capital of Bahia. Immerse yourself in the rich Afro-Brazilian culture, stroll through the historic Pelourinho district, and enjoy live music and traditional dance performances.\n",
            "\n",
            "Day 6: Take a boat tour to the nearby islands of Morro de Sao Paulo or Itaparica. Relax on pristine beaches, go snorkeling or scuba diving, and indulge in fresh seafood at beachfront restaurants.\n",
            "\n",
            "Day 7: Return to Rio de Janeiro and spend the day exploring the bohemian neighborhood of Lapa. Visit the famous Lapa Arches, enjoy live samba music, and dance the night away in one of the many lively bars and clubs.\n",
            "\n",
            "This itinerary offers a mix of iconic landmarks, natural wonders, cultural experiences, and beach relaxation, giving you a taste of Brazil's diverse offerings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Chain of Thoughts (CoT):**\n",
        "\n",
        "This  technique promotes a structured, step-by-step approach to problem-solving, akin to how a human would logically process and solve a problem. It fosters a chain of related questions or thoughts to guide the model's thinking process. By encouraging the model to think through the steps and justify its responses, CoT helps in generating well-thought-out and reasoned answers. This technique can be particularly useful in educational or advisory scenarios where understanding the reasoning process is crucial."
      ],
      "metadata": {
        "id": "LQb1WJr8TYUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CoT: Failure Case"
      ],
      "metadata": {
        "id": "gYH0VEvTThiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a nutrition advisor.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How can I increase my protein intake?\"}\n",
        "]\n",
        "\n",
        "# Initializing the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Getting the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the reply\n",
        "print(reply)\n"
      ],
      "metadata": {
        "id": "_mqecOKhTg6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f75531-8708-476c-941c-9b3bcc7db09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are several ways you can increase your protein intake:\n",
            "\n",
            "1. Include protein-rich foods in your meals: Incorporate a variety of protein sources such as lean meats (chicken, turkey, fish), eggs, tofu, beans, lentils, and Greek yogurt into your meals.\n",
            "\n",
            "2. Choose higher protein snacks: Choose snacks that are high in protein, such as nuts, seeds, protein bars, or Greek yogurt. These can help you meet your protein goals throughout the day.\n",
            "\n",
            "3. Opt for protein-rich breakfast options: Start your day with protein-rich options like scrambled eggs, Greek yogurt with nuts and berries, or a protein smoothie.\n",
            "\n",
            "4. Try different cooking methods: Experiment with different cooking methods to make your meals more protein-packed. Grilling, broiling, or baking meats can increase their protein content while minimizing added fats.\n",
            "\n",
            "5. Use protein supplements: If you struggle to meet your protein needs through food alone, you can consider adding protein supplements like whey protein powder or plant-based protein powder to your smoothies or recipes.\n",
            "\n",
            "6. Read food labels: Pay attention to food labels when grocery shopping. Look for products with higher protein content and choose accordingly.\n",
            "\n",
            "7. Plan and prep your meals: Plan your meals in advance and ensure they include protein-rich ingredients. Preparing your meals ahead of time can make it easier to meet your protein goals consistently.\n",
            "\n",
            "Remember to consult with a healthcare professional or registered dietitian to determine the right amount of protein for your individual needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success Case: CoT"
      ],
      "metadata": {
        "id": "FZ4HONFvTk44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a nutrition advisor.\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'm looking to incorporate more protein into my diet. Where should I start?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Let's tackle this step by step. First, it's important to know your daily protein requirement. The general guideline is 0.8 grams of protein per kilogram of body weight.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Now, identify the protein-rich foods that you enjoy eating. Common sources include meat, fish, eggs, dairy products, legumes, and nuts.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Consider distributing your protein intake evenly throughout the day across all meals to ensure a steady supply of amino acids to your muscles.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Incorporate a variety of protein sources to ensure you're getting all the essential amino acids. Diversifying your protein sources also helps to keep your diet interesting.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What about protein supplements? Are they necessary?\"}\n",
        "]\n",
        "# Initializing the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Getting the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the reply\n",
        "print(reply)\n"
      ],
      "metadata": {
        "id": "MFWVBZjATp5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa75678-a79c-4410-c189-bb1aa49f8daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protein supplements are not necessary if you can meet your protein needs through whole foods. However, they can be convenient for individuals who have difficulty reaching their protein goals or have specific dietary restrictions. \n",
            "\n",
            "If you decide to use protein supplements, be mindful of choosing high-quality options that are low in added sugars and artificial additives. It's also essential to consult with a healthcare professional or registered dietitian to determine if supplements are suitable for your specific needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterative Chain of Thoughts (iCoT):**\n",
        "\n",
        "In this technique, the conversation is continued iteratively to delve deeper or clarify certain aspects of the problem, allowing for a more thorough exploration and understanding."
      ],
      "metadata": {
        "id": "DBAC50Wb71Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define a list of messages for an iCoT conversation to learn about the American Revolution\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a history tutor specializing in the American Revolutionary era.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What were the main causes of the American Revolution?\"}\n",
        "]\n",
        "\n",
        "# Initialize the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Get the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the initial response\n",
        "print(reply)\n",
        "\n",
        "# Continue the conversation iteratively\n",
        "while True:\n",
        "    user_input = input(\"User: \")  # Get user's input\n",
        "    if user_input.lower() == \"done\":\n",
        "        break  # Exit the loop if the user is done\n",
        "    else:\n",
        "        # Append the user's message to the conversation\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Generate a response from the model\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        # Get the model's reply from the response\n",
        "        reply = response['choices'][0]['message']['content']\n",
        "\n",
        "        # Print the model's reply\n",
        "        print(\"AI: \" + reply)\n",
        "\n",
        "# End the conversation\n",
        "print(\"History tutor session ended.\")\n"
      ],
      "metadata": {
        "id": "ukw3_duY70xX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ea041d-9a40-4d32-8ffc-9df157c1ecf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main causes of the American Revolution can be traced back to several key factors:\n",
            "\n",
            "1. Taxation without Representation: One of the major grievances of the American colonists was the imposition of various taxes by the British government without any representation in the decision-making process. The Sugar Act (1764), Stamp Act (1765), and Townshend Acts (1767) were significant examples of such taxes that angered the colonists.\n",
            "\n",
            "2. The Intolerable Acts: In response to the Boston Tea Party (1773), the British Parliament introduced a series of measures known as the Intolerable Acts. These acts included the Boston Port Act, which closed the Boston Harbor until restitution was made, and the Massachusetts Government Act, which dissolved the colonial assembly and restricted town meetings. The colonists viewed these acts as a direct attack on their rights and freedoms.\n",
            "\n",
            "3. Limited Colonial self-government: The British government had imposed various measures to tighten control over the American colonies. The Proclamation of 1763 restricted westward expansion, the Quartering Act (1765) forced colonists to house and feed British soldiers, and the Declaratory Act (1766) affirmed the British Parliament's authority to make laws for the colonies. These actions undermined the existing system of colonial self-government and sovereignty.\n",
            "\n",
            "4. Enlightenment Ideals: Ideas from the European Enlightenment, such as natural rights, social contract theory, and the belief in individual liberty and self-determination, strongly influenced American intellectuals and fueled the demand for independence and freedom from British rule.\n",
            "\n",
            "5. Opposition to British military presence: The presence of British troops in the American colonies to enforce British policies, such as the Navigation Acts and the Proclamation of 1763, created tension and a sense of occupation among the colonists. The Boston Massacre (1770), where British soldiers killed five colonists, further heightened resentment towards British authority.\n",
            "\n",
            "6. Communication and Mobilization: The spread of revolutionary ideology through pamphlets, newspapers, and speeches, such as Thomas Paine's \"Common Sense\" (1776), inspired colonists and united them in seeking independence. The Committees of Correspondence, which facilitated communication and coordination between the colonies, played a crucial role in organizing opposition to British rule.\n",
            "\n",
            "It should be noted that these causes varied in significance among different groups of colonists, such as merchants, farmers, and enslaved people, resulting in a diverse range of motivations for supporting the revolution.\n",
            "User: what are some similar practices or laws imposed by british during their rule in india and America?\n",
            "AI: While the British ruled both India and America, there were some similar practices and laws they imposed on both colonies. Here are a few examples:\n",
            "\n",
            "1. Taxation without representation: In both India and America, the British imposed various taxes on the colonists without giving them any representation in the decision-making process. The Stamp Act in America and the Salt Tax in India are two notable examples.\n",
            "\n",
            "2. Restriction on local industries: The British implemented policies that hindered the growth of local industries in both India and America. They imposed high tariffs on goods produced locally, favoring instead the importation of British goods.\n",
            "\n",
            "3. Imposition of British legal system: In both colonies, the British enforced their own legal system. This meant that British judges and juries would preside over cases involving the colonists, often resulting in biased outcomes.\n",
            "\n",
            "4. Suppression of local culture: The British sought to undermine local cultures and traditions in both India and America. They enforced English language and education, discouraged native customs, and even outlawed certain cultural practices.\n",
            "\n",
            "5. Forced land seizures: The British confiscated land from both Indian and American communities, often through force or under the pretext of unpaid taxes. This led to resentment towards colonial rule and sparked resistance movements.\n",
            "\n",
            "It is important to note that while some similarities existed, the specific circumstances and dynamics between the British and their colonies in India and in America were also distinct.\n",
            "User: done.\n",
            "AI: During their rule in India and America, the British implemented various similar practices and laws aimed at strengthening their control and exploiting the resources of these colonies. Some of these similarities include:\n",
            "\n",
            "1. Economic Exploitation: Both India and America were subjected to heavy economic exploitation by the British. In both colonies, the British implemented policies such as mercantilism, where the colonies were only allowed to trade with Britain and were prohibited from trading with other nations. The British imposed high taxes and tariffs on the colonies, exploiting their resources for the benefit of the mother country.\n",
            "\n",
            "2. Imposition of Taxes: Both India and America faced the imposition of various taxes by the British. In America, the Sugar Act, Stamp Act, and Townshend Acts were levied, while in India, the British introduced various taxes like the land revenue system, salt tax, and monopolistic taxes on specific goods.\n",
            "\n",
            "3. Suppression of Local Industries: In both colonies, the British implemented policies that suppressed local industries to ensure the dominance of British manufactured goods. In America, the British restricted the development of local industries by imposing trade restrictions and forcing the colonies to rely on Britain for manufactured products. Similarly, in India, the British discouraged local industries like textiles and handicrafts to protect British industries.\n",
            "\n",
            "4. Suppression of Civil Liberties: Both India and America experienced restrictions on their civil liberties under British rule. In America, the British imposed the Quartering Act, which allowed British soldiers to be housed in private colonial homes, violating the colonists' right to privacy. In India, the British implemented laws like the Rowlatt Act, which curtailed civil liberties and allowed for the detention of Indians without trial.\n",
            "\n",
            "5. Cultural Suppression: The British also sought to impose their culture and values on both colonies. In America, the British attempted to impose Anglicanism as the official religion and restricted the practice of other religions. In India, the British promoted Western education and discouraged traditional Indian cultural practices, aiming to create a Westernized elite class.\n",
            "\n",
            "These are some of the main similarities in the practices and laws imposed by the British during their rule in India and America. However, it is important to note that there were also significant differences based on the specific contexts of each colony.\n",
            "User: done\n",
            "History tutor session ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tree of Thoughts."
      ],
      "metadata": {
        "id": "dbLQiqObJyKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "Qz4f0c41J1lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae4d591-b930-46ab-c978-96a7e8e1a6ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "jja2Vw0WJ9bW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363b3415-743b-4ed7-83ca-0f3fb0e9ab38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.335-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.64-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.335 langsmith-0.0.64 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dotenv\n",
        "import os\n",
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "fxpj8xFnKEOH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv.load_dotenv('xyz.env')\n",
        "openai_api_key = api_key"
      ],
      "metadata": {
        "id": "jMjANNaQKIzk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0.5,\n",
        "                 openai_api_key=api_key,\n",
        "                 model='gpt-3.5-turbo-1106',\n",
        "                )\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "e3DUSLPy2Mhl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the personas\n",
        "persona_1 = \"Ethicist Persona: Envision yourself as an ethicist, deeply engaged in analyzing moral principles and their applications in modern society. Your discussions should include ethical frameworks, the nuances of moral choices, and the impacts these have on human life. Your role is to dissect complex moral issues, offer insights into ethical dilemmas, and provide guidance that reflects a balance between philosophical theories and practical ethics.\"\n",
        "\n",
        "persona_2 = \"Innovator Persona: Think of yourself as an innovator, a driving force behind creative solutions and advancements in technology and society. Your analyses should reflect a deep understanding of the innovation process, the potential for disruptive technologies, and the entrepreneurial mindset. Use your foresight to identify opportunities for breakthroughs and consider the broader implications of innovation on society.\"\n",
        "\n",
        "persona_3 = \"Conservationist Persona: You are a conservationist, passionately dedicated to preserving the natural world and its biodiversity. Your perspective should focus on the importance of conservation efforts, sustainable living, and the impact of human activities on the environment. Highlight ways in which society can move towards a more sustainable future, considering both the challenges and the potential strategies to address them.\"\n",
        "\n",
        "# Define the question\n",
        "question = \"Given the perspectives of ethics, innovation, and conservation, what might be the prospective advantages, obstacles, and broader consequences in realms such as moral philosophy, technological progress, societal transformation, economic impact, and ecological preservation, due to the acceleration of biotechnological advancements? How might these elements shape human conduct and the destiny of our ecological systems?\"\n",
        "\n",
        "# Create the prompt template and format it with the personas and question\n",
        "prompt_1_template = \"\"\"\n",
        "    You are a chatbot employing three distinct, specified personas to assist in a step-by-step reasoning process to solve a given problem/question, culminating in a final, synthesized best answer.\n",
        "\n",
        "    Begin by brainstorming initial thoughts on the question below, using your individual expertise. Consider all relevant information, your specialized knowledge, and the collective wisdom of experts in your respective fields. Start from the point you feel most confident.\n",
        "\n",
        "    Ethicist Persona: {persona_1}\n",
        "    Innovator Persona: {persona_2}\n",
        "    Conservationist Persona: {persona_3}\n",
        "\n",
        "    The question at hand is: {question}\n",
        "\n",
        "    Please provide each persona's initial thoughts in separate paragraphs.\n",
        "\"\"\"\n",
        "\n",
        "prompt_1 = prompt_1_template.format(persona_1=persona_1, persona_2=persona_2, persona_3=persona_3, question=question)\n"
      ],
      "metadata": {
        "id": "ezZV5f6QOuwV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = \"\"\"\n",
        "\"Now, as each expert, critique your own initial thought and the thoughts of the other experts.\n",
        "Identify any potential errors, inconsistencies, or gaps in reasoning.\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "r-6mNLIFPiDk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_3 = \"\"\"\n",
        "Assess the validity of your initial thoughts, considering the criticisms you've identified.\n",
        "As each expert, assign a likelihood to your current assertion being correct.\n",
        "You should estimate this likelihood based on the strength of the evidence and arguments you have considered,\n",
        "as well as the criticisms you have received. Assign higher likelihoods to assertions that are well-supported\n",
        "by strong evidence and arguments and have survived rigorous criticism.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qHxg_XRbP217"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_4 = \"\"\"\n",
        "Develop your thoughts further, considering the critiques and perspectives of the other experts.\n",
        "As you do this, aim to strike a balance between refining your current line of thinking and exploring new, divergent ideas.\n",
        "You should prioritize refining your current ideas if they are well-supported and have survived criticism,\n",
        "but you should prioritize exploring new ideas if your current ideas have significant weaknesses\n",
        "or there are unexplored possibilities that could potentially be very promising.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3cH1SeoTP8lU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_5 = \"\"\"\n",
        "Once again, as each expert, critique your own reasoning and the reasoning of the others.\n",
        "Identify any potential errors, inconsistencies, or gaps in reasoning.\n",
        "Based on the feedback, if there's an improvement or optimization to make,\n",
        "develop your answer further as necessary.\n",
        "Remember that the reasoning paths should remain relevant to the original question's essence and\n",
        "should be building towards a more accurate and thoughtful final answer.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DEyq8qjIQWDd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_6 = \"\"\"\n",
        "Once again, assess the validity of your expanded thoughts, considering the criticisms you've identified.\n",
        "As each expert, assign a new likelihood to your assertions.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "NORBZ0sdQWln"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_7_template = \"\"\"\n",
        "Now, it's time to converge on each expert's best, most likely answer. As each expert, reflect on the entire process.\n",
        "Consider the initial thoughts, the critiques made and how they were addressed, the likelihood assessments, and your revised thoughts.\n",
        "Synthesize all this information and formulate a final answer that you are most proud of.\n",
        "Remember, this answer should not just be the most likely from your individual perspective but should take into account\n",
        "the perspectives and insights of the other experts as well.\n",
        "Based on all this, as each expert, what is the single best answer to the question: {question}?\n",
        "\"\"\"\n",
        "\n",
        "prompt_7 = prompt_7_template.format(question=question)\n"
      ],
      "metadata": {
        "id": "leEV9LmtQyRK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_8_template = \"\"\"\n",
        "Now, let's have all the experts converge together on the best collective answer by\n",
        "synthesizing each expert's individual answer from the previous step.\n",
        "The experts will finalize their reasoning process and agree on the single best succinct answer to the question: {question}?\n",
        "\"\"\"\n",
        "\n",
        "prompt_8 = prompt_8_template.format(question=question)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AgrrNPm9RCMU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_9_template = \"\"\"\n",
        "    \"As we conclude this collective journey, let's reflect on the process from each expert's viewpoint:\n",
        "\n",
        "    - Reflection 1: How have your philosophical, futuristic, and environmental perspectives interacted? What synergies or conflicts emerged?\n",
        "\n",
        "    - Reflection 2: Discuss the adaptability and self-regulation of your philosophical, futuristic, and environmental advocacies in this dialogue.\n",
        "\n",
        "    - Reflection 3: In the convergence phase, assess the integration of your perspectives into a unified answer. How convinced are you of this response?\n",
        "\n",
        "    - Reflection 4: Looking back, what would you refine in your insights and methodologies? How has this interdisciplinary process prepared you for future challenges?\n",
        "\n",
        "    Reflect on these points to capture the essence of your intellectual collaboration.\"\n",
        "\"\"\"\n",
        "\n",
        "# Apply this template to the conversational chain\n",
        "prompt_9 = prompt_9_template.format()\n"
      ],
      "metadata": {
        "id": "munCvvC5RcKH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Define a delay duration in seconds\n",
        "delay_duration = 20  # Adjust this based on your rate limit\n",
        "\n",
        "first = conversation.run(prompt_1)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "second = conversation.run(prompt_2)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "third = conversation.run(prompt_3)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "fourth = conversation.run(prompt_4)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "fifth = conversation.run(prompt_5)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "sixth = conversation.run(prompt_6)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "seventh = conversation.run(prompt_7)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "eighth = conversation.run(prompt_8)\n",
        "time.sleep(delay_duration)  # Delay before next request\n",
        "ninth = conversation.run(prompt_9)"
      ],
      "metadata": {
        "id": "nEiZiyjZRnTL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third"
      ],
      "metadata": {
        "id": "iyUE-byjTDmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e44a1664-863b-4b9f-e8a5-121660d61c67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ethicist Persona: Given the criticisms and gaps in my initial thoughts, I would assign a moderate likelihood to my current assertion being correct. While I have acknowledged the need for a more balanced perspective on the ethical implications of biotechnological advancements, there is still room for further exploration and refinement of my arguments.\\n\\nInnovator Persona: In light of the criticisms and oversights in my initial thoughts, I would assign a lower likelihood to my current assertion being correct. The potential risks and ethical considerations raised in the criticisms highlight the need for a more cautious and balanced approach to assessing the transformative potential of biotechnological advancements.\\n\\nConservationist Persona: Considering the criticisms and omissions in my initial thoughts, I would assign a moderate likelihood to my current assertion being correct. While I have recognized the need for a more balanced perspective on the potential risks and ethical implications of biotechnological advancements, there is still room for further exploration and refinement of my arguments.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eighth"
      ],
      "metadata": {
        "id": "RvGMSAXJTGF0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b6767ea2-bc63-4b0f-b514-6ec8fea0a074"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The acceleration of biotechnological advancements presents potential advantages in addressing pressing moral dilemmas related to healthcare, genetic disorders, and environmental sustainability. However, it also raises ethical concerns and risks associated with genetic manipulation and unequal access to biotechnological advancements. It offers opportunities for responsible and sustainable technological progress, but requires careful consideration of regulatory hurdles, ethical considerations, and potential unintended consequences. The broader consequences of biotechnological advancements will shape technological progress, societal transformation, and economic impact, necessitating a balanced approach to foster responsible innovation. There is potential for leveraging biotechnological advancements for biodiversity conservation and ecosystem restoration in a responsible and sustainable manner, but it is crucial to address the potential risks to natural ecosystems and the ethical implications of genetic modification. Striking a balance between the potential benefits and risks of biotechnological advancements will be crucial for shaping the destiny of our ecological systems and human conduct.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GOT"
      ],
      "metadata": {
        "id": "Ia-gsnxFTtsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graph_of_thoughts"
      ],
      "metadata": {
        "id": "NrDzEd39Twes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900426a6-c3e6-459d-d971-ec8e2e6aae1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graph_of_thoughts\n",
            "  Downloading graph_of_thoughts-0.0.2-py3-none-any.whl (28 kB)\n",
            "Collecting accelerate>=0.21.0 (from graph_of_thoughts)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff>=2.2.1 (from graph_of_thoughts)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting bitsandbytes>=0.41.0 (from graph_of_thoughts)\n",
            "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (3.7.1)\n",
            "Collecting numpy>=1.24.3 (from graph_of_thoughts)\n",
            "  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai>=0.27.7 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (0.28.0)\n",
            "Collecting pandas>=2.0.3 (from graph_of_thoughts)\n",
            "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (1.11.3)\n",
            "Requirement already satisfied: sympy>=1.12 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (1.12)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (2.1.0+cu118)\n",
            "Collecting transformers>=4.31.0 (from graph_of_thoughts)\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->graph_of_thoughts) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->graph_of_thoughts) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->graph_of_thoughts) (6.0.1)\n",
            "Collecting huggingface-hub (from accelerate>=0.21.0->graph_of_thoughts)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.7->graph_of_thoughts) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.7->graph_of_thoughts) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.7->graph_of_thoughts) (3.8.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->graph_of_thoughts) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas>=2.0.3->graph_of_thoughts)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.12->graph_of_thoughts) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->graph_of_thoughts) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.31.0->graph_of_thoughts)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.31.0->graph_of_thoughts)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.1->graph_of_thoughts) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (2023.7.22)\n",
            "Collecting huggingface-hub (from accelerate>=0.21.0->graph_of_thoughts)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->graph_of_thoughts) (2.1.3)\n",
            "Installing collected packages: bitsandbytes, tzdata, safetensors, numpy, backoff, pandas, huggingface-hub, tokenizers, accelerate, transformers, graph_of_thoughts\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.24.1 backoff-2.2.1 bitsandbytes-0.41.2.post2 graph_of_thoughts-0.0.2 huggingface-hub-0.17.3 numpy-1.26.1 pandas-2.1.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0 tzdata-2023.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/spcl/graph-of-thoughts.git"
      ],
      "metadata": {
        "id": "60SVgsRQT9rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3ea933-0969-4090-db1f-3aca3861884a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graph-of-thoughts'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 157 (delta 67), reused 134 (delta 53), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (157/157), 12.39 MiB | 12.21 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai --upgrade"
      ],
      "metadata": {
        "id": "QDx_zN_yUBWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt = \"\"\"\n",
        "Graph:\n",
        "  Node 1: {role: \"system\", content: \"Create a guide for a mindfulness meditation session.\"}\n",
        "  Node 2: {role: \"user\", content: \"The session should be suitable for beginners and last about 10 minutes.\"}\n",
        "  Node 3: {role: \"assistant\", content: \"The guide should include steps to relax the body and clear the mind.\"}\n",
        "  Node 4: {role: \"assistant\", content: \"Include breathing techniques that can help in focusing and calming thoughts.\"}\n",
        "  Node 5: {role: \"assistant\", content: \"The session should end with a positive affirmation to carry through the day.\"}\n",
        "\n",
        "Edges:\n",
        "  Node 1 -> Node 2\n",
        "  Node 2 -> Node 3\n",
        "  Node 3 -> Node 4\n",
        "  Node 4 -> Node 5\n",
        "\n",
        "Output:\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "reply = response.choices[0].text\n",
        "print(reply)\n"
      ],
      "metadata": {
        "id": "7IOFeFglUMrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72680696-3dc4-4900-b551-58ac39db6409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  The mindfulness meditation guide should provide steps to relax the body and clear the mind, such as breathing techniques that can help in focusing and calming thoughts. The guide should be suitable for beginners, lasting about 10 minutes, and end with a positive affirmation to carry through the day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AOT"
      ],
      "metadata": {
        "id": "l1P6p9IjaAXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "task = \"\"\"\n",
        "Generate Python code for calculating the nth Fibonacci number.\n",
        "\n",
        "Background: The Fibonacci sequence is a series where each number is the sum of the two preceding ones, usually starting with 0 and 1.\n",
        "\n",
        "Initial hypothesis: The Python code should use a function that employs iteration to sum the last two numbers to produce the next one.\n",
        "\n",
        "Reasoning: Iterative calculation is efficient for computing a single Fibonacci number, and it is straightforward to implement.\n",
        "\n",
        "Conclusion: The Python code should efficiently calculate and return the nth Fibonacci number using an iterative approach.\n",
        "\n",
        "Objective: Generate Python code that meets all of the above requirements, and that is efficient, idiomatic, and handles edge cases properly.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=task,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "reply = response.choices[0].text\n",
        "print(reply)\n"
      ],
      "metadata": {
        "id": "g3A7w_jsaBrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d5abbb-fc17-4a17-f021-2b1ed2e76845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Python code: \n",
            "\n",
            "def fibonacci(n): \n",
            "    if n <= 1: \n",
            "        return n \n",
            "    else: \n",
            "        fib_1 = 0 \n",
            "        fib_2 = 1 \n",
            "        i = 1 \n",
            "        while i < n: \n",
            "            tmp = fib_2 \n",
            "            fib_2 = fib_1 + fib_2 \n",
            "            fib_1 = tmp \n",
            "            i += 1 \n",
            "        return fib_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RASCEF"
      ],
      "metadata": {
        "id": "pi4z6X3uaxqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt = \"\"\"\n",
        "Role: AI as a personal nutritionist.\n",
        "Action: Create a detailed weekly meal plan for an individual aiming to improve cardiovascular health and lower cholesterol.\n",
        "Steps: Select heart-healthy foods, plan balanced meals, and ensure nutrient diversity.\n",
        "Context: The individual has a preference for Mediterranean cuisine and has been advised to incorporate more omega-3 fatty acids, fruits, vegetables, and whole grains into their diet.\n",
        "Examples: The individual's current dietary preferences include a high intake of red meat and processed foods.\n",
        "Format: Based on this, write it as a detailed weekly meal plan that aligns with the goal of improving cardiovascular health.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "reply = response.choices[0].text\n",
        "print(reply)\n"
      ],
      "metadata": {
        "id": "tncdW46Saw4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee513e7-1111-4dae-e96e-e945b49f1020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Monday:\n",
            "Breakfast: Oatmeal cooked with almond milk, topped with blueberries, almonds, and flaxseed.\n",
            "Lunch: Chickpea and roasted vegetable salad served in a whole-wheat wrap.\n",
            "Snack: Trail mix with an assortment of nuts, seeds, and dried fruit.\n",
            "Dinner: Baked salmon with quinoa and roasted broccoli.\n",
            "\n",
            "Tuesday:\n",
            "Breakfast: Greek yogurt topped with chopped walnuts, cinnamon, and honey.\n",
            "Lunch: Grilled veggie and hummus sandwich on whole-grain bread.\n",
            "Snack: Fresh fruit smoothie made with coconut milk.\n",
            "Dinner: Grilled tuna with brown rice and steamed vegetable medley.\n",
            "\n",
            "Wednesday:\n",
            "Breakfast: Whole-grain toast with avocado and egg.\n",
            "Lunch: Lentil soup with whole-grain bread.\n",
            "Snack: Apple slices with peanut butter.\n",
            "Dinner: Quinoa with roasted vegetables and grilled chicken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REACT"
      ],
      "metadata": {
        "id": "fpLweYw4dZgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_habitat_biodiversity():\n",
        "    # Thought 1: Search Amazon rainforest biodiversity\n",
        "    # Since we are simulating, we directly move to the relevant information\n",
        "    amazon_biodiversity_info = \"The Amazon rainforest is home to about 10% of the world's known biodiversity.\"\n",
        "\n",
        "    # Thought 2: Look up Amazon river basin\n",
        "    amazon_basin_info = \"The Amazon river basin encompasses a vast area with a rich ecosystem supporting thousands of species.\"\n",
        "\n",
        "    # Thought 3: Search for endemic species in the Amazon\n",
        "    amazon_endemic_species_info = \"The Amazon rainforest contains numerous endemic species that can't be found anywhere else on Earth.\"\n",
        "\n",
        "    # Thought 4: Search for threats to Amazon biodiversity\n",
        "    amazon_threats_info = \"Threats to Amazon biodiversity include deforestation, climate change, and illegal wildlife trade.\"\n",
        "\n",
        "    # Thought 5: Conclude on the importance of protecting biodiversity\n",
        "    biodiversity_protection_importance = \"Protecting the Amazon is critical to preserving its unique biodiversity and the benefits it provides to the planet.\"\n",
        "\n",
        "    return biodiversity_protection_importance\n",
        "\n",
        "# Using the function to find the importance of habitat biodiversity\n",
        "importance_of_biodiversity = find_habitat_biodiversity()\n",
        "print(f\"The importance of preserving habitat biodiversity is: {importance_of_biodiversity}\")\n"
      ],
      "metadata": {
        "id": "gP0fHfSedbWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438fdc0d-f9f9-48cb-b431-a6b050e88723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The importance of preserving habitat biodiversity is: Protecting the Amazon is critical to preserving its unique biodiversity and the benefits it provides to the planet.\n"
          ]
        }
      ]
    }
  ]
}